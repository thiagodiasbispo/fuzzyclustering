{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUlhNVAObqE5"
   },
   "source": [
    "# Implementação do algoritimo completo, sem compromisso com  perfomance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import operator\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import fuzzy\n",
    "import clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXxVfg2r6YrR"
   },
   "source": [
    "# Função match\n",
    "\n",
    "![Match function](./img/match_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kG6AUH5q6lAv"
   },
   "outputs": [],
   "source": [
    "# %load -s cluster_matching_function 'fuzzy.py'\n",
    "def cluster_matching_function(weight_matrix,\n",
    "                              cluster_number,\n",
    "                              element,\n",
    "                              prototypes,\n",
    "                              dissimilarity_matrices):\n",
    "    \"\"\"\n",
    "        :params: weight_matrix: numpy array-like \n",
    "                    matriz K x P de pesos das matrizes de dissimilaridades por cluster\n",
    "                cluster_number: int\n",
    "                    Número do cluster em questão\n",
    "                element: int\n",
    "                    Índice do elemento (entre 0 e N-1)\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "\n",
    "        :return: float\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Criando aliases compatíveis com as variáveis da fórmula\n",
    "    k = cluster_number\n",
    "    D = dissimilarity_matrices\n",
    "    p = len(D)\n",
    "    Gk = prototypes[k]\n",
    "    l = weight_matrix\n",
    "\n",
    "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
    "\n",
    "    return np.dot(l[k], dissimilarities_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdvnqRHK8wBq"
   },
   "source": [
    "# Função objetivo\n",
    "\n",
    "![Objetive function](./img/objective_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUfSEUkfcAnN"
   },
   "outputs": [],
   "source": [
    "# %load -s objective_function 'fuzzy.py'\n",
    "def objective_function(clusters_qtd,\n",
    "                       elements_qtd,\n",
    "                       adequacy_criterion,\n",
    "                       m,\n",
    "                       weight_matrix,\n",
    "                       prototypes,\n",
    "                       dissimilarity_matrices):\n",
    "    \"\"\"\n",
    "        :params: clusters_qtd: int\n",
    "                    Quantidade total de clusters\n",
    "                elements_qtd: int\n",
    "                    Quantidade de elementos da base de dados\n",
    "                adequacy_criterion: numpy array-like\n",
    "                    Matriz u de tamanho N x K contendo a índice de adequação \n",
    "                    de cada elemente a cada cluster\n",
    "                m: int\n",
    "                    Fator de ponderação do índice de adequação\n",
    "                weight_matrix:\n",
    "                     matriz K x P de pesos das matrizes de dissimilaridades por cluster\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "\n",
    "        :return: float\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    u = np.power(adequacy_criterion, m) # Resolvendo a exponeciação de u de uma vez só\n",
    "    l = weight_matrix\n",
    "    D = dissimilarity_matrices\n",
    "    K = clusters_qtd\n",
    "    G = prototypes\n",
    "    N = elements_qtd\n",
    "    match = cluster_matching_function # Criando um alias para reduzir o nome da função de matching\n",
    "  \n",
    "    J = np.array([np.array([u[i, k] * match(l, k, i, G, D) for i in range(N)]).sum() \n",
    "          for k in range(K)])\n",
    "\n",
    "\n",
    "    return J.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzyvZQxb9Iiy"
   },
   "source": [
    "# Protótipos\n",
    "\n",
    "![Prototype function](./img/prototype_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s get_prototypes 'fuzzy.py'\n",
    "def get_prototypes(elements_qtd,\n",
    "                       q,\n",
    "                       m,\n",
    "                       s,\n",
    "                       cluster_number,\n",
    "                       adequacy_criterion,\n",
    "                       dissimilarity_matrices,\n",
    "                       weight_matrix):\n",
    "    G = []\n",
    "    k = cluster_number\n",
    "    D = dissimilarity_matrices\n",
    "    u = np.power(adequacy_criterion, m)\n",
    "    l = np.power(weight_matrix, s)\n",
    "    N = elements_qtd\n",
    "    P = len(D)\n",
    "    \n",
    "    while (len(G) != q):\n",
    "        menor_soma = 999999\n",
    "        menor_indice = None\n",
    "        \n",
    "        for h in range(N): \n",
    "            if h in G:\n",
    "                continue\n",
    "            \n",
    "            dists_p = np.array([D[j][:, h] * l[k,j] for j in range(P)]) #shape: NxP\n",
    "            sums_p = dists_p.sum(axis=0)\n",
    "            soma = np.dot(u[:, k], sums_p)\n",
    "\n",
    "            #soma = sum([u[i,k] * sum([l[k,j] * D[j][i,h] for j in range(P)]) for i in  range(N)])\n",
    "\n",
    "            #print(f\"Somas: {soma2} {soma}\")\n",
    "\n",
    "            if soma < menor_soma:\n",
    "                menor_soma = soma\n",
    "                menor_indice = h\n",
    "                 \n",
    "        G.append(menor_indice)\n",
    "        \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmu24Eka9wdS"
   },
   "source": [
    "# Matriz de relevâcia\n",
    "\n",
    "![Funções de peso](./img/vector_weights_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02tqmGYnBImF"
   },
   "outputs": [],
   "source": [
    "# %load -s compute_relevance_weights 'fuzzy.py'\n",
    "def compute_relevance_weights(clusters_qtd,\n",
    "                              dissimilarity_matrices,\n",
    "                              prototypes,\n",
    "                              elements_qtd,\n",
    "                              adequacy_criterion,\n",
    "                              m):\n",
    "    \"\"\"\n",
    "        :params:\n",
    "                clusters_qtd: int\n",
    "                    Quantidade total de clusters\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                elements_qtd: int\n",
    "                    Quantidade de elementos da base de dados\n",
    "                adequacy_criterion: numpy array-like\n",
    "                    Matriz u de tamanho N x K contendo a índice de adequação \n",
    "                    de cada elemente a cada cluster\n",
    "                m: int\n",
    "                    Fator de ponderação do índice de adequação\n",
    "\n",
    "        :return: numpy array of shape K x P\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    D = dissimilarity_matrices\n",
    "    P = len(D)\n",
    "    G = prototypes\n",
    "    K = clusters_qtd\n",
    "    N = elements_qtd\n",
    "    u = np.power(adequacy_criterion, m)\n",
    "    l = np.zeros((K, P))\n",
    "\n",
    "    def match(element, Dh, Gk):\n",
    "        \"\"\"\n",
    "            Função auxiliar para cálculo de match entre um elemento \n",
    "            qualquer, os protótipos G de um cluster específico e uma matriz \n",
    "            de similaridade específica Dh.\n",
    "        \"\"\"\n",
    "\n",
    "        return Dh[element, Gk].sum()\n",
    "\n",
    "    for k in range(K):\n",
    "        # Calculado o somatório do numerador da equação à esquerda da igualdade\n",
    "        weight_diss_sum1 = np.array([np.array([u[i, k] * match(i, D[h], G[k]) for i in range(N)]).sum()\n",
    "                            for h in range(P)])\n",
    "\n",
    "        weight_diss_sum_prod = np.power(weight_diss_sum1.prod(), 1/P)\n",
    "\n",
    "        for j in range(P):\n",
    "     \n",
    "            # Calculado o somatório do denominador da equação à esquerda da igualdade\n",
    "            weight_diss_sum2 = np.array([u[i, k] * match(i, D[j], G[k])\n",
    "                                    for i in range(N)]).sum()\n",
    "            \n",
    "\n",
    "            # Executando a divisão da fração à esquerda da equação\n",
    "            l[k, j] = weight_diss_sum_prod / weight_diss_sum2\n",
    "\n",
    "    return l\n",
    "\n",
    "\n",
    "# %load -s compute_membership_degree 'fuzzy.py'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grau de pertinência\n",
    "\n",
    "![Fórmula grau de pertinência](./img/membership_degree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s compute_membership_degree 'fuzzy.py'\n",
    "def compute_membership_degree(weight_matrix,\n",
    "                              prototypes,\n",
    "                              clusters_qtd,\n",
    "                              dissimilarity_matrices,\n",
    "                              elements_qtd,\n",
    "                              m):\n",
    "    \"\"\"\n",
    "        :params: weight_matrix: numpy array-like \n",
    "                    matriz K x P de pesos das matrizes de dissimilaridades por cluster\n",
    "                prototypes: list like\n",
    "                    Lista de tamanho K dos protótipos de cada cluster\n",
    "                clusters_qtd: int\n",
    "                    Quantidade total de clusters\n",
    "                dissimilarity_matrices: lista de numpy array\n",
    "                    Lista de matrizes de dissimilaridade\n",
    "                elements_qtd: int\n",
    "                    Quantidade de elementos da base de dados\n",
    "                m: int\n",
    "                    Fator de ponderação do índice de adequação\n",
    "\n",
    "        :return: numpy array NxK\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "    K = clusters_qtd\n",
    "    G = prototypes\n",
    "    D = dissimilarity_matrices\n",
    "    l = weight_matrix\n",
    "    P = len(D)\n",
    "    N = elements_qtd\n",
    "    u = np.zeros((N, K))\n",
    "    \n",
    "    match = cluster_matching_function # Criando um alias para reduzir o nome da função de matching\n",
    "\n",
    "    def ratio(element, k, h):\n",
    "        r = match(l, k, element, G, D) / match(l, h, element, G, D)\n",
    "        #r1 = np.array([l[k,j] * (D[j][element, G[k]].sum()) for j in range(P)]).sum()\n",
    "        #r2 = np.array([l[h,j] * (D[j][element, G[h]].sum()) for j in range(P)]).sum()\n",
    "        #r3 = r1/r2\n",
    "        #print(f\"Ratio: {r} {r3}\")\n",
    "        return np.power(r, 1/(m-1))\n",
    "\n",
    "    for i in range(N):\n",
    "        for k in range(K):\n",
    "            outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
    "            u[i, k] = 1/outter_sum\n",
    "\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SS-G2leHdobn"
   },
   "source": [
    "# Carregando Matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2gEvW3EdWJT"
   },
   "outputs": [],
   "source": [
    "fac_dis, fou_dis, kar_dis = fuzzy.carregar_matrizes_dissimiliradidades()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo completo\n",
    "> Partitioning fuzzy K-medoids clustering algorithms with relevance weight for each dissimilarity matrix estimated locally\n",
    "\n",
    "* Parametros: $K = 10; m = 1.6; T = 150; \\epsilon = 10^{−10};$\n",
    "* Devemos considerar a iniciarlizar do vetor de pesos como sendo 1, já que usamos a equação 9 (MFCMdd-RWL-P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s random_prototypes,executar_treinamento 'fuzzy.py'\n",
    "def random_prototypes(K, N, q, seed):\n",
    "    elements = set(range(N))\n",
    "    protos = []\n",
    "    random.seed(seed)\n",
    "    \n",
    "    for k in range(K):\n",
    "        protos.append(random.sample(elements, q))\n",
    "        elements -= set(protos[-1])\n",
    "\n",
    "    return protos\n",
    "\n",
    "def executar_treinamento(dissimilarity_matrices,\n",
    "                       elements_qtd,\n",
    "                       K=10,\n",
    "                       m=1.6,\n",
    "                       T=150,\n",
    "                       epsilon=10e-10,\n",
    "                       q=2, \n",
    "                       seed=13082020,\n",
    "                       prototipos = None):\n",
    "\n",
    "    D = dissimilarity_matrices\n",
    "    N = elements_qtd\n",
    "    P = len(D)\n",
    "\n",
    "    last_lambda = np.ones((K, P))\n",
    "    last_prototypes = prototipos or random_prototypes(K, N, q, seed)\n",
    "    last_membership_degree = None\n",
    "    last_cost = None\n",
    "    \n",
    "    assert_relevance_weights_prod_one(last_lambda)\n",
    "\n",
    "#     print(\"Passo 0\")\n",
    "#     print(\"Calculando matriz de adequação inicial (u0)\")\n",
    "    u0 = compute_membership_degree(weight_matrix=last_lambda,\n",
    "                                   prototypes=last_prototypes,\n",
    "                                   clusters_qtd=K,\n",
    "                                   dissimilarity_matrices=dissimilarity_matrices,\n",
    "                                   elements_qtd=N,\n",
    "                                   m=m)\n",
    "    \n",
    "#     assert_membership_degree_sum_one(u0)\n",
    "\n",
    "#     print(\"Calculando função de custo inicial (J0)\")\n",
    "    J0 = objective_function(clusters_qtd=K,\n",
    "                            elements_qtd=N,\n",
    "                            adequacy_criterion=u0,\n",
    "                            m=m,\n",
    "                            weight_matrix=last_lambda,\n",
    "                            prototypes=last_prototypes,\n",
    "                            dissimilarity_matrices=dissimilarity_matrices)\n",
    "    \n",
    "    last_membership_degree = u0\n",
    "    last_cost = J0\n",
    "    \n",
    "    for t in range(1, T):\n",
    "#         print(f\"Passo {t}/{T}\")\n",
    "        \n",
    "#         print(\">> Calculando protótipos\")\n",
    "        new_prototypes = [get_prototypes(elements_qtd=N,\n",
    "                                         q=q,\n",
    "                                         m=m,\n",
    "                                         s=1,\n",
    "                                         cluster_number=k,\n",
    "                                         adequacy_criterion=last_membership_degree,\n",
    "                                         dissimilarity_matrices=D,\n",
    "                                         weight_matrix=last_lambda) for k in range(K)]\n",
    "        \n",
    "        #print(\"new_prototypes.shape\", new_prototypes)\n",
    "        \n",
    "#         print(\">> Calculando matriz de relevâncias\")\n",
    "        new_lambda = compute_relevance_weights(clusters_qtd=K,\n",
    "                                               dissimilarity_matrices=D,\n",
    "                                               prototypes=new_prototypes,\n",
    "                                               elements_qtd=N,\n",
    "                                               adequacy_criterion=last_membership_degree,\n",
    "                                               m=m)\n",
    "        \n",
    "#         assert_relevance_weights_prod_one(new_lambda)\n",
    "    \n",
    "#         print(\">> Calculando grau de pertinência\")\n",
    "        new_degree = compute_membership_degree(weight_matrix=new_lambda,\n",
    "                                               prototypes=new_prototypes,\n",
    "                                               clusters_qtd=K,\n",
    "                                               dissimilarity_matrices=dissimilarity_matrices,\n",
    "                                               elements_qtd=N,\n",
    "                                               m=m)\n",
    "    \n",
    "        \n",
    "#         assert_membership_degree_sum_one(new_degree)\n",
    "\n",
    "#         print(\">> Calculando função objetivo\")\n",
    "        new_cost = objective_function(clusters_qtd=K,\n",
    "                                      elements_qtd=N,\n",
    "                                      adequacy_criterion=new_degree,\n",
    "                                      m=m,\n",
    "                                      weight_matrix=new_lambda,\n",
    "                                      prototypes=new_prototypes,\n",
    "                                      dissimilarity_matrices=dissimilarity_matrices)\n",
    "\n",
    "        last_prototypes = new_prototypes\n",
    "        last_lambda = new_lambda\n",
    "        last_membership_degree = new_degree\n",
    "        print(f\">> Cost ({seed}): \", new_cost)\n",
    "        \n",
    "        if abs(last_cost - new_cost) <= epsilon:\n",
    "            last_cost = new_cost\n",
    "            break\n",
    "    \n",
    "        last_cost = new_cost\n",
    "        \n",
    "    data = {\n",
    "        \"cost\":last_cost,\n",
    "        \"membership_degree\":last_membership_degree,\n",
    "        \"prototypes\":last_prototypes,\n",
    "        \"weight_matrix\":last_lambda,\n",
    "        \"times\": t,\n",
    "        \"q\": q,\n",
    "        \"K\":K,\n",
    "        \"m\":m,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executando 1x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Cost:  19534.558421456753\n",
      ">> Cost:  19289.86375808107\n",
      ">> Cost:  19223.236397853263\n",
      ">> Cost:  19138.01160069559\n",
      ">> Cost:  19120.817673828053\n",
      ">> Cost:  19120.68364980515\n",
      ">> Cost:  19120.682802773128\n",
      ">> Cost:  19120.682796660574\n",
      ">> Cost:  19120.682796614812\n",
      ">> Cost:  19120.682796614463\n"
     ]
    }
   ],
   "source": [
    "result = executar_treinamento([fac_dis, fou_dis, kar_dis], 2000, m=1.1, q=2, seed=18082035)\n",
    "\n",
    "result[\"cost\"]\n",
    "\n",
    "# fuzzy.export_best_result(result, \"data/melhor_resultado_todas.pickle\")\n",
    "# fuzzy.export_fuzzy_partitions_to_csv(result, \"data/fuzzy_partitions_todas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executando 100x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMES = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execução 1/100\n",
      ">> Cost:  19361.931283225276\n",
      "Execução 2/100\n",
      ">> Cost:  19216.84946050788\n",
      "Execução 3/100\n",
      ">> Cost:  19418.266638846453\n",
      "Execução 4/100\n",
      ">> Cost:  19266.269069275484\n",
      "Execução 5/100\n",
      ">> Cost:  19039.149006467207\n",
      "Execução 6/100\n",
      ">> Cost:  19262.089666418327\n",
      "Execução 7/100\n",
      ">> Cost:  19220.46965808679\n",
      "Execução 8/100\n",
      ">> Cost:  18958.234629193725\n",
      "Execução 9/100\n",
      ">> Cost:  18962.78641774232\n",
      "Execução 10/100\n",
      ">> Cost:  18990.729309877664\n",
      "Execução 11/100\n",
      ">> Cost:  19313.21469494188\n",
      "Execução 12/100\n",
      ">> Cost:  19200.280164255477\n",
      "Execução 13/100\n",
      ">> Cost:  19081.160036454006\n",
      "Execução 14/100\n",
      ">> Cost:  19574.9884018176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 341, in executar_treinamento\n",
      "    m=m)\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 341, in executar_treinamento\n",
      "    m=m)\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 341, in executar_treinamento\n",
      "    m=m)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in compute_membership_degree\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in compute_membership_degree\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in <listcomp>\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in compute_membership_degree\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 225, in ratio\n",
      "    r = match(l, k, element, G, D) / match(l, h, element, G, D)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in <listcomp>\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 225, in ratio\n",
      "    r = match(l, k, element, G, D) / match(l, h, element, G, D)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in <listcomp>\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 46, in cluster_matching_function\n",
      "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 46, in <listcomp>\n",
      "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 341, in executar_treinamento\n",
      "    m=m)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 46, in cluster_matching_function\n",
      "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 226, in ratio\n",
      "    return np.power(r, 1/(m-1))\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/site-packages/numpy/core/_methods.py\", line 47, in _sum\n",
      "    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 46, in <listcomp>\n",
      "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/thiago/.anaconda3/envs/fuzzy/lib/python3.6/site-packages/numpy/core/_methods.py\", line 47, in _sum\n",
      "    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in compute_membership_degree\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 236, in <listcomp>\n",
      "    outter_sum = np.array([ratio(i, k, h) for h in range(K)]).sum()\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 225, in ratio\n",
      "    r = match(l, k, element, G, D) / match(l, h, element, G, D)\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 46, in cluster_matching_function\n",
      "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
      "  File \"/home/thiago/projects/fuzzyclustering/fuzzy.py\", line 46, in <listcomp>\n",
      "    dissimilarities_sum = np.array([dj[element, Gk].sum() for dj in D])\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6a09f38aa69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                 \u001b[0mreport_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/relatorio_varias_execucoes_todas.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                 \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                 times=TIMES)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfuzzy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_best_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelhor_resultado_todas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/melhor_resultado_todas.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fuzzyclustering/fuzzy.py\u001b[0m in \u001b[0;36mexecutar_algoritmo_varias_vezes\u001b[0;34m(dissimilarity_matrices, N, times, name, report_file, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execução {i+1}/{times}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">> Cost: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cost\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/fuzzy/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/fuzzy/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/fuzzy/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Gk = [[1403,1372],[213,1170],[465,1442],[1380,182],[1793,218],[1212,143],[215,995],[1875,416],[840,693],[1643,1811]]\n",
    "\n",
    "melhor_resultado_todas = fuzzy.executar_algoritmo_varias_vezes([fac_dis, fou_dis, kar_dis], \n",
    "                                                                2000, \n",
    "                                                                m=1.1,\n",
    "                                                                report_file = \"data/relatorio_varias_execucoes_todas.csv\",\n",
    "                                                                q=2,\n",
    "                                                                times=TIMES)\n",
    "\n",
    "fuzzy.export_best_result(melhor_resultado_todas, \"data/melhor_resultado_todas.pickle\")\n",
    "fuzzy.export_fuzzy_partitions_to_csv(melhor_resultado_todas, \"data/fuzzy_partitions_todas.csv\")\n",
    "\n",
    "melhor_resultado_todas[\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_resultado_fac = fuzzy.executar_algoritmo_varias_vezes([fac_dis], 2000, times=TIMES)\n",
    "fuzzy.export_best_result(melhor_resultado_fac, \"data/melhor_resultado_fac.pickle\")\n",
    "fuzzy.export_fuzzy_partitions_to_csv(melhor_resultado_fac, \"data/fuzzy_partitions_fac.csv\")\n",
    "\n",
    "melhor_resultado_fac[\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_resultado_fou = fuzzy.executar_algoritmo_varias_vezes([fou_dis], 2000, times=TIMES)\n",
    "fuzzy.export_best_result(melhor_resultado_fou, \"data/melhor_resultado_fou.pickle\")\n",
    "fuzzy.export_fuzzy_partitions_to_csv(melhor_resultado_fou, \"data/fuzzy_partitions_fou.csv\")\n",
    "\n",
    "melhor_resultado_fou[\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_resultado_kar = fuzzy.executar_algoritmo_varias_vezes([kar_dis], 2000, times=TIMES)\n",
    "fuzzy.export_best_result(melhor_resultado_kar, \"data/melhor_resultado_kar.pickle\")\n",
    "fuzzy.export_fuzzy_partitions_to_csv(melhor_resultado_kar, \"data/fuzzy_partitions_kar.csv\")\n",
    "\n",
    "melhor_resultado_kar[\"cost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterinando melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# qs = list(range(2, 6))\n",
    "# ms = np.arange(1., 2.1, .1)\n",
    "\n",
    "# fuzzy.buscar_melhores_parametros(qs, ms, [fac_dis, fou_dis, kar_dis])\n",
    "# fuzzy.buscar_melhores_parametros(qs, ms, [fac_dis], file_name=\"data/melhores_parametros_fac.csv\"), times= 10)\n",
    "# fuzzy.buscar_melhores_parametros(qs, ms, [fou_dis], file_name=\"data/melhores_parametros_fou.csv\"), times = 10)\n",
    "# fuzzy.buscar_melhores_parametros(qs, ms, [kar_dis], file_name=\"data/melhores_parametros_kar.csv\"), times = 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_clusterizar_lazy_version.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
